from utils import *
from transformers import AutoTokenizer
from paper_classif_data_handler import *

class PaperClassificationPredictor():
	"""
	Handles prediction based on a trained model
	"""
	def __init__(self, model_huggingface_version, checkpoint_filepath, descriptive_labels):
		"""
		:param model_huggingface_version: HuggingFace model version to load the pretrained model weights from
    :param checkpoint_filepath: saved checkpt to load the model from 
    :param descriptive_labels: descriptive labels corresponding to the labels [0, 1] generated by the model
		"""

		self.device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
		self.model = AutoModelForSequenceClassification.from_pretrained(model_huggingface_version, num_labels=2)
		checkpoint = torch.load(checkpoint_filepath, map_location = self.device)
		self.model.load_state_dict(checkpoint['model_state_dict'])
		self.model.to(self.device)
		self.model.eval()
		self.tokenizer = AutoTokenizer.from_pretrained(model_huggingface_version)
		self.class_labels = ClassLabel(num_classes = 2, names = descriptive_labels)
	  
	def predict(self, sentence):
		"""
		Generates predictions for a sentence using the trained model

		:returns: predicted labels
		"""
		with torch.no_grad():
			inputs = self.tokenizer(sentence, return_tensors = "pt", truncation = True).to(self.device)
			outputs = self.model(**inputs)
			logits = outputs.logits
			predictions = torch.argmax(logits, dim=-1).cpu().numpy()
			predicted_labels = [self.class_labels.int2str(int(x)) for x in predictions]
		return predicted_labels


if __name__ == '__main__':
	parser = argparse.ArgumentParser()

	parser.add_argument('--checkpoint-filepath', type=str, default = 'checkpts/checkpt_biomed_roberta_title_abstract_512_10_epochs', help = 'Location of saved checkpoint file.')
	parser.add_argument('--input-file', type=str, default = 'data/val_paper_classif.csv', help = 'Input file. Should contain title/abstract information')
	parser.add_argument('--output-file', type=str, default = 'output_dir/paper_classif_preds.csv', help = 'Output file containing predictions on input_file')
	parser.add_argument('--model-name', type=str, default='biomed_roberta', help = "Name of model to try. Can be one of: ['bert', 'biobert', 'scibert', 'pubmedbert', 'pubmedbert_pmc', 'bluebert', 'bluebert_mimic3', 'sapbert', 'sapbert_mean_token', 'bioelectra', 'bioelectra_pmc', 'electramed', 'biomed_roberta', 'biomed_roberta_chemprot', 'biomed_roberta_rct_500']")
	parser.add_argument('--descriptive-labels', type=str, default=['not-bio-resource', 'bio-resource'], help = "Descriptive labels corresponding to the [0, 1] numeric scores")
	parser.add_argument('--predictive-field', type=str, default='title_abstract', help = "Field in the dataframes to use for prediction. Can be one of ['title', 'abstract', 'title-abstract']")
	parser.add_argument('--labels-field', type=str, default='curation_score', help = "Field in the dataframes corresponding to the scores (0, 1)")
	parser.add_argument('--pred-only', type=bool, default=False, help = 'True if the df provided has no true labels. If there are true labels, metrics can be computed.')
	        
	args, _ = parser.parse_known_args()

	print(f'args={args}')
	model_huggingface_version = MODEL_TO_HUGGINGFACE_VERSION[args.model_name]
	predictor = PaperClassificationPredictor(model_huggingface_version, args.checkpoint_filepath, args.descriptive_labels)

	# Load data in a DataLoader
	print('Processing dataset ...')
	data_handler = DataHandler(model_huggingface_version, args.input_file, pred_only = args.pred_only)
	data_handler.parse_abstracts_xml()
	data_handler.concatenate_title_abstracts()
	print('Finished processing dataset!')

	# Predict labels
	print('Starting prediction ...')
	predicted_labels = []
	sentences = data_handler.train_df[args.predictive_field].values
	print('Generating predictions for ', len(sentences), 'sentences!')
	for sentence in sentences:
		predicted_label = predictor.predict(sentence)[0]
		predicted_labels.append(predicted_label)
	
	data_handler.train_df['predicted_label'] = predicted_labels
	pred_df = data_handler.train_df
	print(data_handler.train_df.columns)
	if 'curation_score' in data_handler.train_df.columns.values and not args.pred_only:
		true_labels = [predictor.class_labels.int2str(int(x)) for x in data_handler.train_df['curation_score'].values]
		pred_df['true_label'] = true_labels
		pred_df = data_handler.train_df
	print('Finished prediction!')
	print(pred_df[:20])

	# Save labels to file
	pred_df.to_csv(args.output_file)
	print('Saved predictions to', args.output_file)